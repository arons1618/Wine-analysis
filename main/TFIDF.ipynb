{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.48.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from nltk) (2020.11.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, r2_score, mean_squared_error\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the previous section just performing regression analysis, k-nearest neighbors, linear discriminant analysis and other forms of algorithms is not very good at predicting the points given to a bottle of wine. Below we attempt to see if taking in a more specialized feature can have an impact on the accuracy of predicting the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF for reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function that will assign a classification to a row in the dataframe based off the score that is passed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_wine_points(score):\n",
    "    if score <= 83:\n",
    "        return 'ok'\n",
    "    elif score <= 85:\n",
    "        return 'below average'\n",
    "    elif score <= 86:\n",
    "        return 'average'\n",
    "    elif score <= 88:\n",
    "        return 'good'\n",
    "    elif score <= 94:\n",
    "        return 'great'\n",
    "    else:\n",
    "        return 'perfect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the dataframe into values respective of its classification. This is done inorder to have an equal samples from each range. We then take a sample of 2000 from each classification.\n",
    "\n",
    "**Note:** a sample is being used due to the kernel running out of memory due to the jupyter notebook kernel running out of memory when performing analysis otherwise as a result predictions depend on the sample that is given as it is obtained randomly. Furthermore these predictions vary with $\\pm1\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv(\"wine.csv\")\n",
    "wine_df['classification'] = wine_df['points'].apply(classify_wine_points)\n",
    "reviews_ok = wine_df.loc[wine_df['classification'] == 'ok']\n",
    "reviews_ba = wine_df.loc[wine_df['classification'] == 'below average']\n",
    "reviews_a = wine_df.loc[wine_df['classification'] == 'average']\n",
    "reviews_good = wine_df.loc[wine_df['classification'] == 'good']\n",
    "reviews_great = wine_df.loc[wine_df['classification'] == 'great']\n",
    "reviews_p = wine_df.loc[wine_df['classification'] == 'perfect']\n",
    "\n",
    "reviews = reviews_ok.sample(2000).append(reviews_ba.sample(2000))\\\n",
    ".append(reviews_a.sample(2000))\\\n",
    ".append(reviews_good.sample(2000))\\\n",
    ".append(reviews_great.sample(2000))\\\n",
    ".append(reviews_p.sample(2000)).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are focusing on the description (review) of the wine here is an example of one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A soft, simple, fruity Merlot. Tastes like a cherry, blackberry, roasted almond, cocoa and cinnamon granola bar, melted into wine.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['description'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove punctuation and other special characters and convert everything to lower case as it is not significat that words be capitalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = []\n",
    "\n",
    "for descrip in reviews['description']:\n",
    "    line = re.sub(r'\\W', ' ', str(descrip))\n",
    "    line = line.lower()\n",
    "    descriptions.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use `TfidfVectorizer`, in order to understand what it is what term frequency-inverse document frequency (TF_IDT) is must be explained first. TF-IDF is a measure that evaluates the relevancy that a word has for a document inside a collection of other documents. Furthermore TF-IDF can be defined as the following:\n",
    "\n",
    "$ \\text{Term Frequency (TF)} = \\frac{\\text{Frequency of a word}}{\\text{Total number of words in document}} $\n",
    "\n",
    "$ \\text{Inverse Document Frequency (IDF)} = \\log{\\frac{\\text{Total number of documents}}{\\text{Number of documents that contain the word}}} $\n",
    "\n",
    "$ \\text{TF-IDF} = \\text{TF} \\cdot \\text{IDF} $\n",
    "\n",
    "In turn what `TfidfVectorizer` gives us is a list of feature lists that we can use as estimators for prediction. \n",
    "\n",
    "The parameters for `TfidfVectorizer` are max_features, max_df, and stop_words. \n",
    "max_features tells us to only look at the top n features of the total document\n",
    "max_df causes the vectorizer to ignore terms that have a document frequency strictly higher than the given threshold. In our case because a float is its value we ignore words that appear in more that 80% of documents\n",
    "stop_words allows us to pass in a set of stop words. Stop words are words that add little to no meaning to a sentence. This includes words such as i, our, him, and her. \n",
    "Folling this we fit and transform the data then we xplit it into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reviews['points'].values\n",
    "vec = TfidfVectorizer(max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "X = vec.fit_transform(descriptions).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is split into a training and test set we can use a machine learning algorithm in order to predict the outcome. Which in this case we attempt to predict the points (score) given to a bottle of wine. We do this with `RandomForestRegressor()`. given that its a random forest algorithm it takes the average of the decision trees that were created and used as estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we then need to determine how accurate this algorithm is given the estimates returned from the random forest regression. We do this by using `score()` which returns the coefficient of determination of the prediction ($r^2$). In other words it is the observed y variation that can be explained by the and by the regression model. We also perform a 10 fold cross validation and then taking the mean of the scores returned and compute the residual mean squared error of the model (rmse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: 0.6470310143879181\n",
      "rmse score: 2.6484481808535856\n"
     ]
    }
   ],
   "source": [
    "print('r2 score:', rfr.score(X_test, y_test))\n",
    "print('rmse score:', mean_squared_error(y_test, pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6106014527800235"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs = cross_val_score(rfr, X_test, y_test, cv=10)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is solely based off the description of the wine. As you can see this is a large improvement over any sort of prediction that was done with linear regression, k-nearest neighbor or linear discriminant analysis. However, it is still not the best for several reasons. The first being the r2 score, or how well our model is at making predictions. There is still a large portion of the data that is not being accurately predicted. \n",
    "\n",
    "The other issue pertains to when the model does fail at making the prediction. given that the rmse score is very high this can be interpreted as when we do fail we fail rather spectacualary. However, given that the context of this problem is making a prediction for determining arbitrary integer point values for bottles of wine, failing spectaculary is not necesarilly what is occuring. The rmse value tells use that with each incorrect prediction we are about 2.5 points off. However, it is still less than ideal.\n",
    "\n",
    "Below we see if we can improve upon these shortcomings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we factorize the other features of the dataset, specifically those mentioned in `str_cols` by factorizing categorical variables we are able to include them as estimators for our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>variety</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  variety  province  region_1  winery\n",
       "0        0        0         0         0       0\n",
       "1        0        0         0         1       1\n",
       "2        0        1         0         2       2\n",
       "3        0        2         1         3       3\n",
       "4        1        3         2        -1       4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign numerical values to string columns\n",
    "str_cols = ['country', 'variety', 'province', 'region_1', 'winery']\n",
    "factorized_wine = reviews[str_cols].copy()\n",
    "for col in str_cols:\n",
    "    factorized_wine[col] = pd.factorize(reviews[col])[0]\n",
    "\n",
    "factorized_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we combine the features that were obtained from `TfidfVectorizer` with the features that we just factorized in there respective rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_X = factorized_wine.to_numpy('int64')\n",
    "X = np.concatenate((wine_X,X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_fac = RandomForestRegressor()\n",
    "rfr_fac.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_pred = rfr_fac.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform the same actions as above to determine the accuracy of the prediction. That is we use `score()` and perform a 10 fold cross validation and then take the mean of the scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: 0.8008655035381019\n",
      "rmse score: 1.9892824753329192\n"
     ]
    }
   ],
   "source": [
    "print('r2 score:', rfr_fac.score(X_test, y_test))\n",
    "print('rmse score:', mean_squared_error(y_test, fac_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7592042244065704"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fac_cvs = cross_val_score(rfr_fac, X_test, y_test, cv=10)\n",
    "fac_cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the scores computed above the accuracy drastically improves when the features from performing TF-IDF are combined with those from factorizing categorical variables in the dataset. We also improve upon the error when the model fails to make the correct prediction as it is about 2 points off instead of 2.5 points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
