{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.48.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (0.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the previous section just performing regression analysis, k-nearest neighbors, linear discriminant analysis and other forms of algorithms is not very good at predicting the points given to a bottle of wine. Below we attempt to see if taking in a more specialized feature can have an impact on the accuracy of predicting the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function that will assign a classification to a row in the dataframe based off the score that is passed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_wine_points(score):\n",
    "    if score <= 83:\n",
    "        return 'ok'\n",
    "    elif score <= 85:\n",
    "        return 'below average'\n",
    "    elif score <= 86:\n",
    "        return 'average'\n",
    "    elif score <= 88:\n",
    "        return 'good'\n",
    "    elif score <= 94:\n",
    "        return 'great'\n",
    "    else:\n",
    "        return 'perfect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the dataframe into values respective of its classification. This is done inorder to have an equal samples from each range. We then take a sample of 2000 from each classification.\n",
    "\n",
    "**Note:** a sample is being used due to the kernel running out of memory due to the jupyter notebook kernel running out of memory when performing analysis otherwise as a result predictions depend on the sample that is given as it is obtained randomly. Furthermore these predictions vary with $\\pm1\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv(\"wine.csv\")\n",
    "wine_df['classification'] = wine_df['points'].apply(classify_wine_points)\n",
    "reviews_ok = wine_df.loc[wine_df['classification'] == 'ok']\n",
    "reviews_ba = wine_df.loc[wine_df['classification'] == 'below average']\n",
    "reviews_a = wine_df.loc[wine_df['classification'] == 'average']\n",
    "reviews_good = wine_df.loc[wine_df['classification'] == 'good']\n",
    "reviews_great = wine_df.loc[wine_df['classification'] == 'great']\n",
    "reviews_p = wine_df.loc[wine_df['classification'] == 'perfect']\n",
    "\n",
    "reviews = reviews_ok.sample(2000).append(reviews_ba.sample(2000))\\\n",
    ".append(reviews_a.sample(2000))\\\n",
    ".append(reviews_good.sample(2000))\\\n",
    ".append(reviews_great.sample(2000))\\\n",
    ".append(reviews_p.sample(2000)).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are focusing on the description (review) of the wine here is an example of one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basic everyday Pinot Noir. It's dry, with simple cola and cherry flavors, and a grating acidity.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['description'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove punctuation and other special characters and convert everything to lower case as it is not significat that words be capitalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = []\n",
    "\n",
    "for descrip in reviews['description']:\n",
    "    line = re.sub(r'\\W', ' ', str(descrip))\n",
    "    line = line.lower()\n",
    "    descriptions.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use `TfidfVectorizer`, in order to understand what it is what term frequency-inverse document frequency (TF_IDT) is must be explained first. TF-IDF is a measure that evaluates the relevancy that a word has for a document inside a collection of other documents. Furthermore TF-IDF can be defined as the following:\n",
    "\n",
    "$ \\text{Term Frequency (TF)} = \\frac{\\text{Frequency of a word}}{\\text{Total number of words in document}} $\n",
    "\n",
    "$ \\text{Inverse Document Frequency (IDF)} = \\log{\\frac{\\text{Total number of documents}}{\\text{Number of documents that contain the word}}} $\n",
    "\n",
    "$ \\text{TF-IDF} = \\text{TF} \\cdot \\text{IDF} $\n",
    "\n",
    "In turn what `TfidfVectorizer` gives us is a list of feature lists that we can use as estimators for prediction. \n",
    "\n",
    "The parameters for `TfidfVectorizer` are max_features, max_df, and stop_words. \n",
    "max_features tells us to only look at the top n features of the total document\n",
    "max_df causes the vectorizer to ignore terms that have a document frequency strictly higher than the given threshold. In our case because a float is its value we ignore words that appear in more that 80% of documents\n",
    "stop_words allows us to pass in a set of stop words. Stop words are words that add little to no meaning to a sentence. This includes words such as i, our, him, and her. \n",
    "Folling this we fit and transform the data then we xplit it into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reviews['points'].values\n",
    "vec = TfidfVectorizer(max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "X = vec.fit_transform(descriptions).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is split into a training and test set we can use a machine learning algorithm in order to predict the outcome. Which in this case we attempt to predict the points (score) given to a bottle of wine. We do this with `RandomForestRegressor()`. given that its a random forest algorithm it takes the average of the decision trees that were created and used as estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we then need to determine how accurate this algorithm is given the estimates returned from the random forest regression. We do this by using `score()` and by performing a 10 fold cross validation and then taking the mean of the scores returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590980437958478"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.613404338579916"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs = cross_val_score(rfr, X_test, y_test, cv=10)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is solely based off the description of the wine. As you can see this is a large improvement over any sort of prediction that was done with linear regression, k-nearest neighbor or linear discriminant analysis. However, it is still not the best as there is still a large portion of the data that is not being accurately predicted, below we see if it can be improved upon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we factorize the other features of the dataset, specifically those mentioned in `str_cols` by factorizing categorical variables we are able to include them as estimators for our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>variety</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>177</td>\n",
       "      <td>-1</td>\n",
       "      <td>3450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>3077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  variety  province  region_1  winery\n",
       "0            0        0         0         0       0\n",
       "1            1        1         1         1       1\n",
       "2            0        2         2         2       2\n",
       "3            0        3         3         3       3\n",
       "4            0        4         2         4       4\n",
       "...        ...      ...       ...       ...     ...\n",
       "11995        0        3         2        13    5412\n",
       "11996        0        2         2         2    3622\n",
       "11997       21       11       177        -1    3450\n",
       "11998        0       13         2       125    3077\n",
       "11999        0       13         2         2    4353\n",
       "\n",
       "[12000 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign numerical values to string columns\n",
    "str_cols = ['country', 'variety', 'province', 'region_1', 'winery']\n",
    "factorized_wine = reviews[str_cols].copy()\n",
    "for col in str_cols:\n",
    "    factorized_wine[col] = pd.factorize(reviews[col])[0]\n",
    "\n",
    "factorized_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we combine the features that were obtained from `TfidfVectorizer` with the features that we just factorized in there respective rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_X = factorized_wine.to_numpy('int64')\n",
    "X = np.concatenate((wine_X,X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf_count = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform the same actions as above to determine the accuracy of the prediction. That is we use `score()` and perform a 10 fold cross validation and then take the mean of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7998418678785136"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7627166607378533"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs = cross_val_score(rfr, X_test, y_test, cv=10)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the scores computed above the accuracy drastically improves when the features from performing TF-IDF are combined with those from factorizing categorical variables in the dataset. The resulting improvement is by nearly 15%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
